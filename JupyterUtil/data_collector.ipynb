{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 画像の収集\n",
    "1. ' TrainData ' 以下のフォルダに入る\n",
    "2. 任意のフォルダで ' googleimagesdownload -k _KEYWORD_ -l 5 ' を実行する\n",
    "\n",
    "    [参考ページ](https://co.bsnws.net/article/295)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## キーワードとDL数の設定\n",
    "キーワードの設定\n",
    "dl数の設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path: C:\\Users\\init\\Documents\\PythonScripts\\EnhanceImageFromUserPreference\\TrainData\\Illust\n",
      "keyword: モネ\n",
      "dl_num: 3\n"
     ]
    }
   ],
   "source": [
    "def set_key_and_dl_num():\n",
    "    from tkinter import Tk, filedialog\n",
    "\n",
    "    root = Tk()\n",
    "    root.attributes('-topmost', True)\n",
    "    root.withdraw()\n",
    "    root.lift()\n",
    "    root.focus_force()\n",
    "    temp = filedialog.askdirectory(title='画像を保存するフォルダを選択してください')\n",
    "    root.destroy()\n",
    "\n",
    "    if not temp:\n",
    "        print('フォルダが選択されませんでした')\n",
    "    else:\n",
    "        from pathlib import Path\n",
    "        from tkinter.filedialog import askdirectory\n",
    "        \n",
    "        global download_dir_path\n",
    "        download_dir_path = Path(temp)\n",
    "\n",
    "        #　検索キーワードを設定\n",
    "        global keyword\n",
    "        keyword = 'モネ'\n",
    "        \n",
    "         #　dl数を設定\n",
    "        global dl_num\n",
    "        dl_num = 3\n",
    "\n",
    "        print(f'path: {download_dir_path}')\n",
    "        print(f'keyword: {keyword}')\n",
    "        print(f'dl_num: {dl_num}')\n",
    "        \n",
    "set_key_and_dl_num()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ダウンロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Item no.: 1 --> Item name = \\u30e2\\u30cd\n",
      "Evaluating...\n",
      "Starting Download...\n",
      "Completed Image ====> 1.A1T1PLop9qL.jpg\n",
      "Completed Image ====> 2.monet-main.jpg\n",
      "Completed Image ====> 3.000000001420.jpg\n",
      "\n",
      "Errors: 0\n",
      "\n",
      "\n",
      "Everything downloaded!\n",
      "Total errors: 0\n",
      "Total time taken: 3.000023365020752 Seconds\n"
     ]
    }
   ],
   "source": [
    "def download():\n",
    "    dl_dir_path = str(download_dir_path)\n",
    "    !googleimagesdownload -k $keyword -l $dl_num -o $dl_dir_path\n",
    "\n",
    "download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 画像ごとにフォルダを作る"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dl_path: C:\\Users\\init\\Documents\\PythonScripts\\EnhanceImageFromUserPreference\\TrainData\\Illust\\モネ\n",
      "dl_num: 3\n",
      "-- complete! --\n"
     ]
    }
   ],
   "source": [
    "def format_dir():\n",
    "    dl_path = str(download_dir_path/keyword)\n",
    "    %run -i C:\\Users\\init\\Documents\\PythonScripts\\EnhanceImageFromUserPreference\\JupyterUtil\\image_folder_formatter\\main.py -p $dl_path -n $dl_num\n",
    "        \n",
    "format_dir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 作業フォルダの選択"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "work path: C:\\Users\\init\\Documents\\PythonScripts\\EnhanceImageFromUserPreference\\TrainData\\Illust\\モネ\n",
      "work images path:\n",
      "\tC:\\Users\\init\\Documents\\PythonScripts\\EnhanceImageFromUserPreference\\TrainData\\Illust\\モネ\\1\\1.A1T1PLop9qL.jpg\n",
      "\tC:\\Users\\init\\Documents\\PythonScripts\\EnhanceImageFromUserPreference\\TrainData\\Illust\\モネ\\2\\2.monet-main.jpg\n",
      "\tC:\\Users\\init\\Documents\\PythonScripts\\EnhanceImageFromUserPreference\\TrainData\\Illust\\モネ\\3\\3.000000001420.jpg\n"
     ]
    }
   ],
   "source": [
    "def select_work_dir():\n",
    "    from tkinter import Tk, filedialog \n",
    "\n",
    "    root = Tk()\n",
    "    root.attributes('-topmost', True)\n",
    "    root.withdraw()\n",
    "    root.lift()\n",
    "    root.focus_force()\n",
    "\n",
    "    initialdir = 'C:/Users/init/Documents/PythonScripts/EnhanceImageFromUserPreference/TrainData'\n",
    "    temp = filedialog.askdirectory(title='作業フォルダを選択してください', initialdir=initialdir)\n",
    "    root.destroy()\n",
    "\n",
    "    if not temp:\n",
    "        print('フォルダが選択されませんでした')\n",
    "    else:\n",
    "        from tkinter.filedialog import askdirectory\n",
    "        from pathlib import Path\n",
    "        import itertools\n",
    "        from pprint import pprint\n",
    "\n",
    "        global work_dir_path \n",
    "        work_dir_path = Path(temp)\n",
    "\n",
    "        global work_image_path_list \n",
    "        work_image_path_list = [path for path in itertools.chain(work_dir_path.glob('**/*.png'), work_dir_path.glob('**/*.jpg'))]\n",
    "        work_image_path_list.sort()\n",
    "        \n",
    "select_work_dir()\n",
    "\n",
    "print(f'work path: {str(work_dir_path)}')\n",
    "print('work images path:')\n",
    "for path in work_image_path_list:\n",
    "    print(f'\\t{str(path)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# モデルタイプの選択"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model type: compare\n"
     ]
    }
   ],
   "source": [
    "model_type = 'compare'\n",
    "print(f'model type: {model_type}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 学習データを作る"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## スコアをつける\n",
    "1. ’ 1 ’の画像に対して100枚の補正画像を生成する\n",
    "2. ’ 1、2、3 ’の画像に対して10枚の補正画像を生成する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_path: C:\\Users\\init\\Documents\\PythonScripts\\EnhanceImageFromUserPreference\\TrainData\\Illust\\モネ\\1\\1.A1T1PLop9qL.jpg\n",
      "save_file_path: C:\\Users\\init\\Documents\\PythonScripts\\EnhanceImageFromUserPreference\\TrainData\\Illust\\モネ\\1\\scored_parameter\\data.csv\n",
      "generate_num: 100\n",
      "image_path: C:\\Users\\init\\Documents\\PythonScripts\\EnhanceImageFromUserPreference\\TrainData\\Illust\\モネ\\1\\1.A1T1PLop9qL.jpg\n",
      "save_file_path: C:\\Users\\init\\Documents\\PythonScripts\\EnhanceImageFromUserPreference\\TrainData\\Illust\\モネ\\1\\scored_parameter\\test.csv\n",
      "generate_num: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:File `\"'C:\\\\Users\\\\init\\\\Documents\\\\PythonScripts\\\\EnhanceImageFromUserPreference\\\\TrainDataGenerator\\\\tournament\\\\tournament_comparer.py'.py\"` not found.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_path: C:\\Users\\init\\Documents\\PythonScripts\\EnhanceImageFromUserPreference\\TrainData\\Illust\\モネ\\3\\3.000000001420.jpg\n",
      "save_file_path: C:\\Users\\init\\Documents\\PythonScripts\\EnhanceImageFromUserPreference\\TrainData\\Illust\\モネ\\3\\scored_parameter\\test.csv\n",
      "generate_num: 10\n",
      "--- complete ! ---\n"
     ]
    }
   ],
   "source": [
    "def scoring():\n",
    "    known_image_path = work_image_path_list[0]\n",
    "    save_file_path = str(known_image_path.parent/'scored_parameter'/'data.csv')\n",
    "    known_image_path = str(known_image_path)\n",
    "    %run -i C:\\Users\\init\\Documents\\PythonScripts\\EnhanceImageFromUserPreference\\TrainDataGenerator\\tournament\\tournament_comparer.py -p $known_image_path -n 100 -s $save_file_path\n",
    "\n",
    "    for image_path in work_image_path_list:\n",
    "        save_file_path = str(image_path.parent/'scored_parameter'/'test.csv')\n",
    "        %run -i C:\\Users\\init\\Documents\\PythonScripts\\EnhanceImageFromUserPreference\\TrainDataGenerator\\tournament\\tournament_comparer.py -p $image_path -n 10 -s $save_file_path\n",
    "\n",
    "scoring()\n",
    "print('--- complete ! ---')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## スコアデータのグラフ化\n",
    "グラフは ' 研究成果/画像/_カテゴリ_/グラフ ' に保存する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param_paths: ['C:/Users/init/Documents/PythonScripts/PredictEvaluationFromHumanPreference/TrainData/Photography/Artificial/salad/1/scored_parameter/data1.csv']\n",
      "graph_type: scatter\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x29d87e25c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from tkinter import Tk, filedialog\n",
    "root = Tk()\n",
    "root.attributes('-topmost', True)\n",
    "root.withdraw()\n",
    "root.lift()\n",
    "root.focus_force()\n",
    "\n",
    "temp = filedialog.askopenfilenames(title='パラメータファイルの選択', filetypes=[('', '.csv')])\n",
    "root.destroy()\n",
    "\n",
    "if not temp:\n",
    "     print('ファイルが選択されませんでした')\n",
    "else:\n",
    "    param_path = ' '.join(temp)\n",
    "    %run -i C:\\Users\\init\\Documents\\PythonScripts\\PredictEvaluationFromHumanPreference\\TrainDataGenerator\\param_score_graphizer.py -p $param_path -g scatter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## スコアデータからTFRecords形式へ変換\n",
    "保存先のデータセットフォルダ名を設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/init/Documents/PythonScripts/EnhanceImageFromUserPreference/TrainData/Illust/モネ/1/scored_parameter/data.csv\n",
      "dataset_dir_path: C:\\Users\\init\\Documents\\PythonScripts\\EnhanceImageFromUserPreference\\TrainData\\Illust\\モネ\\1\\compare\\tfrecords\\data1\n",
      "param_paths: ['C:/Users/init/Documents/PythonScripts/EnhanceImageFromUserPreference/TrainData/Illust/モネ/1/scored_parameter/data.csv']\n",
      "image_path: C:\\Users\\init\\Documents\\PythonScripts\\EnhanceImageFromUserPreference\\TrainData\\Illust\\モネ\\1\\1.A1T1PLop9qL.jpg\n",
      "model_type: compare\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\init\\Documents\\PythonScripts\\EnhanceImageFromUserPreference\\TrainDataGenerator\\TFRecordsMaker\\switchable_writer.py:11: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2033/2033 [00:04<00:00, 453.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- complete ! ---\n"
     ]
    }
   ],
   "source": [
    "def convert():\n",
    "    from tkinter import Tk, filedialog\n",
    "    image_path = work_image_path_list[0]\n",
    "    \n",
    "    #　保存先のデータセットフォルダ名を設定\n",
    "    dataset_name = 'data1'\n",
    "    dataset_dir_path = image_path.parent/model_type/'tfrecords'/dataset_name\n",
    "    if not dataset_dir_path.exists():\n",
    "        dataset_dir_path.mkdir(parents=True)\n",
    "    \n",
    "    root = Tk()\n",
    "    root.attributes('-topmost', True)\n",
    "    root.withdraw()\n",
    "    root.lift()\n",
    "    root.focus_force()\n",
    "    \n",
    "    initialdir = str(image_path.parent/'scored_parameter')\n",
    "    temp = filedialog.askopenfilenames(title='パラメータファイルの選択', filetypes=[('', '.csv')], initialdir=initialdir)\n",
    "    root.destroy()\n",
    "\n",
    "    if not temp:\n",
    "         print('ファイルが選択されませんでした')\n",
    "    else:\n",
    "        param_paths = ' '.join(temp)\n",
    "        print(param_paths)\n",
    "        dataset_dir_path = str(dataset_dir_path)\n",
    "        \n",
    "        %run -i C:\\Users\\init\\Documents\\PythonScripts\\EnhanceImageFromUserPreference\\TrainDataGenerator\\TFRecordsMaker\\ScoredParamConverter\\scored_param_converter.py \\\n",
    "            -d $dataset_dir_path -p $param_paths -i $image_path -t $model_type\n",
    "\n",
    "convert()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 好みの学習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデル読み込み関数の定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_load_dir_path():\n",
    "    from tkinter import Tk, filedialog\n",
    "    root = Tk()\n",
    "    root.attributes('-topmost', True)\n",
    "    root.withdraw()\n",
    "    root.lift()\n",
    "    root.focus_force()\n",
    "    \n",
    "    train_dir_path = work_image_path_list[0].parent/model_type\n",
    "    summary_dir_path = train_dir_path/'summary'\n",
    "    \n",
    "    initialdir = str(summary_dir_path)\n",
    "    load_dir_path = filedialog.askdirectory(title='モデルをロードするフォルダを選択')\n",
    "    root.destroy()\n",
    "    \n",
    "    return load_dir_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習\n",
    "使用するデータセットの設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_dir_path: C:\\Users\\init\\Documents\\PythonScripts\\EnhanceImageFromUserPreference\\TrainData\\Illust\\モネ\\1\\compare\\tfrecords\\data1\n",
      "summary_dir_path: C:\\Users\\init\\Documents\\PythonScripts\\EnhanceImageFromUserPreference\\TrainData\\Illust\\モネ\\1\\compare\\summary\n",
      "load_dir_path: None\n",
      "model_type: compare\n",
      "use_jupyter: True\n",
      "Epoch 1/10\n",
      "29/30 [============================>.] - ETA: 18s - loss: 0.70 - ETA: 13s - loss: 0.59 - ETA: 10s - loss: 0.53 - ETA: 9s - loss: 0.4857 - ETA: 8s - loss: 0.426 - ETA: 7s - loss: 0.378 - ETA: 6s - loss: 0.347 - ETA: 6s - loss: 0.329 - ETA: 6s - loss: 0.331 - ETA: 5s - loss: 0.329 - ETA: 5s - loss: 0.350 - ETA: 4s - loss: 0.359 - ETA: 4s - loss: 0.361 - ETA: 4s - loss: 0.363 - ETA: 3s - loss: 0.355 - ETA: 3s - loss: 0.370 - ETA: 3s - loss: 0.368 - ETA: 2s - loss: 0.367 - ETA: 2s - loss: 0.367 - ETA: 2s - loss: 0.360 - ETA: 2s - loss: 0.351 - ETA: 1s - loss: 0.343 - ETA: 1s - loss: 0.336 - ETA: 1s - loss: 0.335 - ETA: 1s - loss: 0.336 - ETA: 0s - loss: 0.347 - ETA: 0s - loss: 0.345 - ETA: 0s - loss: 0.344 - ETA: 0s - loss: 0.3439"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "You must feed a value for placeholder tensor 'predict_model_2/input_6' with dtype float and shape [?,32,32,3]\n\t [[{{node predict_model_2/input_6}}]]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\Documents\\PythonScripts\\EnhanceImageFromUserPreference\\UserPreferencePredictor\\predictor_trainer.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     trainable_model.train(dataset[TRAIN], log_dir_path=log_dir_path,\n\u001b[1;32m---> 63\u001b[1;33m                           valid_dataset=dataset[VALIDATION])\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[0mtrainable_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlog_dir_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\PythonScripts\\EnhanceImageFromUserPreference\\UserPreferencePredictor\\Model\\Compare\\ranknet.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, dataset, log_dir_path, valid_dataset)\u001b[0m\n\u001b[0;32m     58\u001b[0m         self.trainable_model.fit(dataset, epochs=epochs,\n\u001b[0;32m     59\u001b[0m                                  \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m                                  \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalid_dataset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m                                  validation_steps=10)\n\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\UnityML\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    778\u001b[0m           \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m           \u001b[0mvalidation_freq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m           steps_name='steps_per_epoch')\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\UnityML\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[1;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[0;32m    407\u001b[0m           \u001b[0mvalidation_in_fit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    408\u001b[0m           \u001b[0mprepared_feed_values_from_dataset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 409\u001b[1;33m           steps_name='validation_steps')\n\u001b[0m\u001b[0;32m    410\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_results\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    411\u001b[0m         \u001b[0mval_results\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mval_results\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\UnityML\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[1;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[0;32m    272\u001b[0m           \u001b[1;31m# `ins` can be callable in tf.distribute.Strategy + eager case.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    273\u001b[0m           \u001b[0mactual_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mins\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 274\u001b[1;33m           \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mactual_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    275\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    276\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[0mis_dataset\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\UnityML\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[1;32m-> 3292\u001b[1;33m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[0;32m   3293\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3294\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\UnityML\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1458\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1459\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'predict_model_2/input_6' with dtype float and shape [?,32,32,3]\n\t [[{{node predict_model_2/input_6}}]]"
     ]
    }
   ],
   "source": [
    "def train():\n",
    "    train_dir_path = work_image_path_list[0].parent/model_type\n",
    "    train_image_path = [path for path in train_dir_path.parent.iterdir() if path.is_file()][0]\n",
    "    \n",
    "    #　使用するデータセットの設定\n",
    "    dataset_name = 'data1'\n",
    "    dataset_dir_path = str(train_dir_path/'tfrecords'/dataset_name)\n",
    "\n",
    "    summary_dir_path = str(train_dir_path/'summary')\n",
    "\n",
    "    load_dir_path = get_load_dir_path()\n",
    "\n",
    "    if load_dir_path:\n",
    "        %run -i C:\\Users\\init\\Documents\\PythonScripts\\EnhanceImageFromUserPreference\\UserPreferencePredictor\\predictor_trainer.py \\\n",
    "            -d $dataset_dir_path -s $summary_dir_path  -l $load_dir_path -t $model_type -j\n",
    "    else:\n",
    "        %run -i C:\\Users\\init\\Documents\\PythonScripts\\EnhanceImageFromUserPreference\\UserPreferencePredictor\\predictor_trainer.py \\\n",
    "            -d $dataset_dir_path -s $summary_dir_path -t $model_type -j\n",
    "        \n",
    "train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 学習したモデルの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load_dir_path: C:/Users/init/Documents/PythonScripts/EnhanceImageFromUserPreference/TrainData/Illust/モネ/1/Compare/summary/0705/1609\n"
     ]
    }
   ],
   "source": [
    "load_dir_path = get_load_dir_path()\n",
    "\n",
    "print(f'load_dir_path: {load_dir_path}')\n",
    "\n",
    "if not load_dir_path:\n",
    "    print('warning: フォルダが選択されていません')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 評価値高い順に並び替え\n",
    "1. 既知画像に対する出力を ' 研究成果/画像/_カテゴリ_/評価値とスコアの比較/既知 ' に保存する\n",
    "2. 未知画像に対する出力を ' 研究成果/画像/_カテゴリ_/評価値とスコアの比較/未知_i ' に保存する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load_dir_path: C:/Users/init/Documents/PythonScripts/EnhanceImageFromUserPreference/TrainData/Illust/モネ/1/Compare/summary/0705/1609\n",
      "image_path: C:\\Users\\init\\Documents\\PythonScripts\\EnhanceImageFromUserPreference\\TrainData\\Illust\\モネ\\1\\1.A1T1PLop9qL.jpg\n",
      "param_file_path: C:\\Users\\init\\Documents\\PythonScripts\\EnhanceImageFromUserPreference\\TrainData\\Illust\\モネ\\1\\scored_parameter\\test.csv\n",
      "model_type: compare\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Model' object has no attribute 'load'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\Documents\\PythonScripts\\EnhanceImageFromUserPreference\\UserPreferencePredictor\\evaluate_visualizer.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m         \u001b[0mpredict_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_dir_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ロードができなかったため終了します'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\PythonScripts\\EnhanceImageFromUserPreference\\UserPreferencePredictor\\Model\\Compare\\ranknet.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(self, load_dir_path)\u001b[0m\n\u001b[0;32m     69\u001b[0m                           str(Path(save_dir_path) /\n\u001b[0;32m     70\u001b[0m                               RankNet.PREDICTABLE_MODEL_FILE_NAME)\n\u001b[1;32m---> 71\u001b[1;33m                           )\n\u001b[0m\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m         self.trainable_model.save_weights(\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Model' object has no attribute 'load'"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:File `\"'C:\\\\Users\\\\init\\\\Documents\\\\PythonScripts\\\\EnhanceImageFromUserPreference\\\\UserPreferencePredictor\\\\evaluate_visualizer.py'.py\"` not found.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "load_dir_path: C:/Users/init/Documents/PythonScripts/EnhanceImageFromUserPreference/TrainData/Illust/モネ/1/Compare/summary/0705/1609\n",
      "image_path: C:\\Users\\init\\Documents\\PythonScripts\\EnhanceImageFromUserPreference\\TrainData\\Illust\\モネ\\3\\3.000000001420.jpg\n",
      "param_file_path: C:\\Users\\init\\Documents\\PythonScripts\\EnhanceImageFromUserPreference\\TrainData\\Illust\\モネ\\3\\scored_parameter\\test.csv\n",
      "model_type: compare\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Model' object has no attribute 'load'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\Documents\\PythonScripts\\EnhanceImageFromUserPreference\\UserPreferencePredictor\\evaluate_visualizer.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m         \u001b[0mpredict_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_dir_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ロードができなかったため終了します'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\PythonScripts\\EnhanceImageFromUserPreference\\UserPreferencePredictor\\Model\\Compare\\ranknet.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(self, load_dir_path)\u001b[0m\n\u001b[0;32m     69\u001b[0m                           str(Path(save_dir_path) /\n\u001b[0;32m     70\u001b[0m                               RankNet.PREDICTABLE_MODEL_FILE_NAME)\n\u001b[1;32m---> 71\u001b[1;33m                           )\n\u001b[0m\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m         self.trainable_model.save_weights(\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Model' object has no attribute 'load'"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for image_path in work_image_path_list:\n",
    "    param_file_path = str(image_path.parent/'scored_parameter'/'test.csv')\n",
    "    %run -i C:\\Users\\init\\Documents\\PythonScripts\\EnhanceImageFromUserPreference\\UserPreferencePredictor\\evaluate_visualizer.py -l $load_dir_path -i $image_path -p $param_file_path -t $model_type\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 最適化\n",
    "1. 既知画像に対する出力を ' 研究成果/画像/_カテゴリ_/最適化/既知 ' に保存する\n",
    "2. 未知画像に対する ' 研究成果/画像/_カテゴリ_/最適化/未知_i ' に保存する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load_dir_path: C:/Users/init/Documents/PythonScripts/EnhanceImageFromUserPreference/TrainData/Illust/モネ/1/Compare/summary/0705/1609\n",
      "image_path: C:\\Users\\init\\Documents\\PythonScripts\\EnhanceImageFromUserPreference\\TrainData\\Illust\\モネ\\1\\1.A1T1PLop9qL.jpg\n",
      "model_type: compare\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Model' object has no attribute 'load'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\Documents\\PythonScripts\\EnhanceImageFromUserPreference\\ParameterOptimizer\\main.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     41\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'{str(arg)}: {str(getattr(args, arg))}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_init_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_dir_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m     \u001b[0mimage_enhancer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImageEnhancer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\PythonScripts\\EnhanceImageFromUserPreference\\ParameterOptimizer\\main.py\u001b[0m in \u001b[0;36m_init_model\u001b[1;34m(load_dir_path, model_type)\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRankNet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mload_dir_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'学習済みモデルをロードできなかったため終了します'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\PythonScripts\\EnhanceImageFromUserPreference\\UserPreferencePredictor\\Model\\Compare\\ranknet.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(self, load_dir_path)\u001b[0m\n\u001b[0;32m     69\u001b[0m         self.predictable_model.save_weights(\n\u001b[0;32m     70\u001b[0m             str(Path(save_dir_path) /\n\u001b[1;32m---> 71\u001b[1;33m                 RankNet.PREDICTABLE_MODEL_FILE_NAME)\n\u001b[0m\u001b[0;32m     72\u001b[0m         )\n\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Model' object has no attribute 'load'"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:File `\"'C:\\\\Users\\\\init\\\\Documents\\\\PythonScripts\\\\EnhanceImageFromUserPreference\\\\ParameterOptimizer\\\\main.py'.py\"` not found.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load_dir_path: C:/Users/init/Documents/PythonScripts/EnhanceImageFromUserPreference/TrainData/Illust/モネ/1/Compare/summary/0705/1609\n",
      "image_path: C:\\Users\\init\\Documents\\PythonScripts\\EnhanceImageFromUserPreference\\TrainData\\Illust\\モネ\\3\\3.000000001420.jpg\n",
      "model_type: compare\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Model' object has no attribute 'load'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\Documents\\PythonScripts\\EnhanceImageFromUserPreference\\ParameterOptimizer\\main.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     41\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'{str(arg)}: {str(getattr(args, arg))}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_init_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_dir_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m     \u001b[0mimage_enhancer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImageEnhancer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\PythonScripts\\EnhanceImageFromUserPreference\\ParameterOptimizer\\main.py\u001b[0m in \u001b[0;36m_init_model\u001b[1;34m(load_dir_path, model_type)\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRankNet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mload_dir_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'学習済みモデルをロードできなかったため終了します'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\PythonScripts\\EnhanceImageFromUserPreference\\UserPreferencePredictor\\Model\\Compare\\ranknet.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(self, load_dir_path)\u001b[0m\n\u001b[0;32m     69\u001b[0m         self.predictable_model.save_weights(\n\u001b[0;32m     70\u001b[0m             str(Path(save_dir_path) /\n\u001b[1;32m---> 71\u001b[1;33m                 RankNet.PREDICTABLE_MODEL_FILE_NAME)\n\u001b[0m\u001b[0;32m     72\u001b[0m         )\n\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Model' object has no attribute 'load'"
     ]
    }
   ],
   "source": [
    "for image_path in work_image_path_list:\n",
    "    image_path = str(image_path)\n",
    "    %run -i C:\\Users\\init\\Documents\\PythonScripts\\EnhanceImageFromUserPreference\\ParameterOptimizer\\main.py -l $load_dir_path -i $image_path -t $model_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
